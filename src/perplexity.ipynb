{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-OR3SnjiFJS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10623/team project\n",
        "!pwd"
      ],
      "metadata": {
        "id": "GcAzM6T1iPnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "DG9v_48d6C_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def html2raw(text):\n",
        "  pattern = re.compile(r'<[^>]*>')\n",
        "  cleaned_text = re.sub(pattern, '', text)\n",
        "\n",
        "  return cleaned_text\n"
      ],
      "metadata": {
        "id": "-mX-emNJJGUp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def json2str(json_file_path):\n",
        "  data = None\n",
        "  with open(json_file_path, 'r', encoding='utf-16') as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "  title = data['title']['raw']\n",
        "  abstract = html2raw(data['abstract']['raw'])\n",
        "\n",
        "  desc = []\n",
        "  for k in data['description']:\n",
        "    if 'raw' in data['description'][k]:\n",
        "      text = data['description'][k]['raw']\n",
        "      desc.append(html2raw(text))\n",
        "  description = \"\".join(desc)\n",
        "\n",
        "  return title + \"\\n\\n\" + abstract + \"\\n\\n\" + description\n"
      ],
      "metadata": {
        "id": "SgV3NSCS8_6u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = \"samples\"\n",
        "patents = []\n",
        "for filename in os.listdir(directory):\n",
        "  path = os.path.join(directory, filename)\n",
        "  patents.append(json2str(path))\n",
        "\n",
        "print(len(patents))\n"
      ],
      "metadata": {
        "id": "1wLp3wGqAEWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\\n\\n\".join(patents)"
      ],
      "metadata": {
        "id": "Ig5SeR3qC-ps"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "# baseline\n",
        "# model_id = \"openai-community/gpt2\"\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "# tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
        "\n",
        "# our pre-trained models\n",
        "model = AutoModelForCausalLM.from_pretrained(\"genai-proj/gpt2-100000\", use_auth_token='genai-models').to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"genai-proj/gpt2-100000\", use_auth_token='genai-models')"
      ],
      "metadata": {
        "id": "Mj9Z2_UriTNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = tokenizer(input_text, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "iTmurdvHiTLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encodings['input_ids'].shape)"
      ],
      "metadata": {
        "id": "zTLyVJuS0HNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_length = model.config.n_positions\n",
        "stride = 1024\n",
        "seq_len = encodings.input_ids.size(1)\n",
        "\n",
        "nlls = []\n",
        "prev_end_loc = 0\n",
        "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
        "    end_loc = min(begin_loc + max_length, seq_len)\n",
        "    trg_len = end_loc - prev_end_loc\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        neg_log_likelihood = outputs.loss\n",
        "\n",
        "    nlls.append(neg_log_likelihood)\n",
        "\n",
        "    prev_end_loc = end_loc\n",
        "    if end_loc == seq_len:\n",
        "        break\n",
        "\n",
        "ppl = torch.exp(torch.stack(nlls).mean())\n"
      ],
      "metadata": {
        "id": "ypI_VKhVi3_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ppl)\n"
      ],
      "metadata": {
        "id": "eC3ecS1NHPi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRKNPI9-PXnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}